Сетевое взаимодействие — это общение между процессами и контейнерами. Сетевая связь Docker в основном используется для установки связи между контейнерами Docker и связи с внешним миром.

Docker обрабатывает связь между контейнерами, создавая сеть мостов по умолчанию, в большинстве случаев этого достаточно для нормальной работы.

Docker позволяет создавать несколько типов сетевых драйверов:

- `bridge` или Мост это сетевой драйвер по умолчанию. Бридж сеть используется, когда ваши приложения запускаются в автономных контейнерах, которые должны взаимодействовать между собой, наглядный пример Nginx + MySQL
- `host` или Хост это сетевой драйвер для автономных контейнеров, удаленная сетевая изоляция между контейнером и Docker хостом. Данный драйвер доступен только для docker-swarm с поддержкой Docker 17.06 и выше.
- `overlay/overlay2` или Оверлей Наложенная сеть это сетевой драйвер для соединения несколько демонов Docker между собой и которые позволяют docker-swarm службам взаимодействовать друг с другом. Вы также можете использовать оверлейные сети для облегчения связи между docker-swarm и автономным контейнером или между двумя отдельными контейнерами на разных Docker демонах. Эта стратегия устраняет необходимость выполнения маршрутизации на уровне ОС между этими контейнерами
- `macvlan` или Маквлан это сетевой драйвер, который позволяют назначать MAC-адрес контейнеру, делая его отображаемым как физическое устройство в вашей сети. Docker демон направляет трафик на контейнеры по их MAC-адресам. Использование macvlan драйвера иногда является лучшим выбором при работе с устаревшими приложениями, которые ожидают, что они будут напрямую подключены к физической сети
- `none` или Нон это сетевой драйвер, который умеет отключать всю сеть для контейнеров. Обычно используется в сочетании с пользовательским сетевым драйвером
- `network plugins` можете установить и использовать сторонние сетевые плагины с Docker контейнерами. Эти плагины доступны в Docker Store или у сторонних поставщиков услуг

Где и что лучше использовать:

- `bridge` или Мост лучше всего использовать для связи нескольких контейнеров на одном и том же Docker хосте. Можно юзать docker-compose и выберать даную сеть для такой связки
- `host` или Хост лучше всего юзать, когда сетевой стек не должен быть изолирован от хоста Docker, но вы хотите, чтобы другие аспекты контейнера были изолированы
- `overlay/overlay2` или Оверлей Наложенная сеть лучше всего заюзать, когда вам нужны контейнеры, работающие на разных Docker хостах для связи, или, когда несколько приложений работают вместе, используя docker-swarm
- `macvlan` или Маквлан сети лучше всего использовать, когда вы переходите с VM/дедикейта  на контейнеры или хотите, чтобы ваши контейнеры выглядели как физические хосты в вашей сети, каждый с уникальным MAC-адресом
- `network plugins` сетевые плагины позволяют интегрировать Docker со специализированными сетевыми стеками

## Соединение контейнеров

При запуске контейнера можно указать порты к внешнему миру, имя и сеть в которой он будет находится, например:
```
docker run --name plot --network mynetwork -p 5000:5000 -d flask
```

Но что если наш с вами сервис состоит из 4 контейнеров и в процессе работы мы планируем часто манипулировать ими. Постоянно писать длинные команды для работы с контейнерами будет очень долгим процессом. В таком случае нам поможет compose файл.

# Что такое docker compose
`docker-compose` — это инструмент для **определения и запуска мультиконтейнерных Docker-приложений**. Он позволяет описывать инфраструктуру приложения (контейнеры, сети, тома, переменные окружения и т.д.) в YAML-файле (`docker-compose.yml`), а затем запускать всё одной командой.

Представим что мы хотим запустить сеть, внутри которой друг с другом будут взаимодействовать 4 контейнера. Мы поместим их в одну сеть и помимо этого выделим им том. Тома или volumes нужны для сохранения данных, например из базы, чтобы при пересоздании контейнера, наполнение бд сохранилось. 

Рассмотрим на примере приложения:
```
project/
│
├── ckecker/
│   ├── main.py
│   └── requirements.txt
│
├── plot/
│   ├── index.html
│   └── requirements.txt
└── compose.yml
```
ссылка на репозиторий с кодом: https://github.com/SkullPiercer/solva-compose

Начнем с `Dockerfile` для обоих директорий:
```
FROM python:3.11.9-alpine

WORKDIR /app

ENV PYTHONUNBUFFERED=1

RUN pip install --upgrade pip

COPY requirements.txt .

RUN pip install --no-cache-dir -r requirements.txt

COPY . .

CMD ["python", "app.py"]
```

Теперь опишем один файл для создания контейнеров, сетей и volumes.
```
services:
  mymongo:
    image: mongo
    volumes:
      - mongodata:/data/db

    environment:
      - MONGO_INITDB_ROOT_USERNAME=root
      - MONGO_INITDB_ROOT_PASSWORD=example

  dbbrowser:
    image: mongo-express
    ports:
      - 8081:8081

    environment:
      - ME_CONFIG_MONGODB_ADMINUSERNAME=root
      - ME_CONFIG_MONGODB_ADMINPASSWORD=example
      - ME_CONFIG_MONGODB_URL=mongodb://root:example@mymongo:27017/

    depends_on:
      - mymongo

  api:
    build: ./checker
    image: app:1.0.0
    depends_on:
      - mymongo

  web:
    build: ./plot
    image: plot:1.0.0
    ports:
      - 127.0.0.1:5000:5000

    depends_on:
      - api

volumes:
  mongodata:
```

Разберемся, что тут происходит

Секция `services` описывает **контейнеры**, которые будут запускаться. Каждый блок внутри — это **отдельный сервис (контейнер)**.

```
mymongo:
  image: mongo
  volumes:
    - mongodata:/data/db
  environment:
    - MONGO_INITDB_ROOT_USERNAME=root
    - MONGO_INITDB_ROOT_PASSWORD=example
```
Сервис `mymongo` использует официальный образ MongoDB. Он запускает базу данных и использует именованный том `mongodata`, который подключается к директории `/data/db` внутри контейнера. Именно в этой папке MongoDB хранит все свои данные, а подключение тома позволяет сохранить их при перезапуске или пересборке контейнера. Кроме того, при запуске задаются переменные окружения `MONGO_INITDB_ROOT_USERNAME` и `MONGO_INITDB_ROOT_PASSWORD`, с помощью которых создаётся root-пользователь базы данных — это нужно, чтобы другой контейнер мог подключиться к Mongo с правами администратора.

```
dbbrowser:
  image: mongo-express
  ports:
    - 8081:8081
  environment:
    - ME_CONFIG_MONGODB_ADMINUSERNAME=root
    - ME_CONFIG_MONGODB_ADMINPASSWORD=example
    - ME_CONFIG_MONGODB_URL=mongodb://root:example@mymongo:27017/
  depends_on:
    - mymongo
```
Сервис `dbbrowser` предназначен для веб-доступа к базе данных. Он использует образ `mongo-express`, который представляет собой интерфейс, доступный через браузер. В файле указывается, что порт 8081 контейнера должен быть доступен на порту 8081 хоста, чтобы пользователь мог открыть браузер и подключиться к `mongo-express` по адресу `http://localhost:8081`. Также через переменные окружения задаются логин и пароль для подключения к Mongo, а в переменной `ME_CONFIG_MONGODB_URL` указывается полный адрес подключения: `mongodb://root:example@mymongo:27017/`. Здесь `mymongo` — это имя другого сервиса, и в контексте Docker Compose это работает как DNS-имя: контейнеры, запущенные вместе, могут обращаться друг к другу по этим именам. Блок `depends_on` указывает, что `dbbrowser` должен запускаться после `mymongo`. Это не гарантирует, что Mongo будет полностью готова, но гарантирует порядок запуска.

```
api:
  build: ./checker
  image: app:1.0.0
  depends_on:
    - mymongo
```
Сервис `api` описывает собственное backend-приложение. Вместо готового образа используется параметр `build`, который указывает на локальную директорию `./checker`. В ней должен находиться `Dockerfile`, по которому Docker соберёт образ. После сборки образу присваивается имя `app:1.0.0`. Сервис `api` зависит от `mymongo`, что указывается через `depends_on`. Таким образом, база данных будет запущена до того, как стартует backend.

```
web:
  build: ./plot
  image: plot:1.0.0
  ports:
    - 127.0.0.1:5000:5000
  depends_on:
    - api
```
Сервис `web` представляет frontend-часть или веб-интерфейс системы. Он также собирается из локальной папки (`./plot`) и получает имя образа `plot:1.0.0`. Через директиву `ports` пробрасывается порт 5000, но только на `localhost` (127.0.0.1). Это означает, что приложение будет доступно изнутри той машины, на которой запущен Docker, но не из внешней сети. Сервис `web` зависит от `api`, и его запуск начнётся только после того, как будет поднят backend.

```
volumes:
  mongodata:
```
В самом конце файла указан раздел `volumes`, где определяется том `mongodata`. Это именованный том, который Docker создаёт и управляет им независимо от конкретного контейнера. Он нужен, чтобы MongoDB могла хранить данные между перезапусками. Если удалить контейнер `mymongo`, а том оставить — при следующем запуске база данных не будет пуста, потому что данные останутся сохранёнными в томе.


Хотя в `docker-compose.yml` явно не указана секция `networks`, Docker Compose автоматически создаёт внутреннюю виртуальную сеть, в которую помещаются все сервисы. Благодаря этому, каждый контейнер может обращаться к другим контейнерам по имени, указанному в `services`. Это позволяет, например, `mongo-express` подключаться к Mongo по имени `mymongo`, а не по IP-адресу.
Она могла бы выглядеть так, если бы мы хотели указать ее явно
```
networks:
  default:
    driver: bridge
```

В целом, этот `docker-compose.yml` описывает простую, но уже достаточно близкую к реальной структуру: база данных, веб-интерфейс к базе, API-приложение и frontend-интерфейс. Все компоненты связаны между собой через внутреннюю сеть, их порядок запуска определён с помощью `depends_on`, а данные Mongo сохраняются вне контейнера благодаря `volumes`.

Полная цепочка зависимостей
```
web (порт 5000, build ./plot)
  ↑
api (build ./checker)
  ↑
mymongo (MongoDB, сохраняет данные в mongodata)
↓
dbbrowser (порт 8081, mongo-express)
```

Запускаем `docker compose` и проверяем чтобы все работало корректно
```
docker compose up -d
```
флаг -d позволяет нам продолжать вводить команды терминал.