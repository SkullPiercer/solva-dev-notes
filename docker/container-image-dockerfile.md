## Что такое Docker?

Docker — это платформа для создания, распространения и запуска контейнеров. Контейнер — это легковесная, изолированная среда, в которой можно запускать приложения. Контейнеры основаны на образах, которые определяют, что будет внутри.

Для ознакомления можно посмотреть видео: [https://www.youtube.com/watch?v=aZTL2zRmOnA&ab_channel=MerionAcademy](https://www.youtube.com/watch?v=aZTL2zRmOnA&ab_channel=MerionAcademy)

Перед началом работы нужно убедиться, что Docker установлен и доступен:
```
docker version
```

Показывает подробную информацию о клиенте и сервере Docker (демоне).
```
docker -v
```
Выводит краткую версию клиента Docker.

---
# Пулим образ с DockerHub
Для того чтобы собрать контейнер нам необходим образ (image). Который мы можем или собрать самостоятельно или скачать из DockerHub.

Качаем образ с docker hub и сохраняет локально
```
docker pull hello-world
```

Ищем образ локально, если его нет, то ищет и качает его с docker hub, и запускает контейнер
```
docker run hello-world
```

Если все прошло корректно то мы увидим
```
Hello from Docker!
```

Давайте рассмотрим статус наших контейнеров
```
docker ps
```

Мы ничего не увидим потому что команда возвращает статусы только запущенных контейнеров, если мы хотим увидеть все то нужно запустить с ключом -a
```
docker ps -a
```

Также мы можем получить список всех установленных образов
```
docker images
```

# Ubuntu в контейнере
Если мы просто сделаем 
```
docker run ubuntu
```
То контейнер сразу остановится потому что внутри нет ни одного процесса, спулим другой командой

```
docker run --name ubunta -it ubuntu
```
Тут у нас ключи:
--name - задаем имя контейнеру
-it запускаем внутри созданного контейнера терминал

В качестве эксперимента, внутри контейнера можно установить что-либо в эту ос.
```
apt-get update
apt-get install nano -y
```

Теперь мы можем пользоваться редактором nano.

# Dockerfile
Когда тебе **нужно многократно создавать один и тот же контейнер**, уже с настроенной средой, зависимостями и файлами — **лучше всего использовать `Dockerfile`**.

`Dockerfile` — это **текстовый файл со сценарными инструкциями**, который описывает, **как собрать Docker-образ**. Он нужен для автоматизации создания среды, в которой будет работать приложение.

Создадим директорию с двумя файлами:
```
project/
│
├── app.py
├── Dockerfile
```

Файл app.py
```
import time

SLEEP_TIME = 2

while True:
    print(time.strftime("%Y-%m-%d %H:%M:%S", time.localtime()))
    time.sleep(SLEEP_TIME)
```

Начнем заполнять Dockerfile для того чтобы собрать контейнер с Python и запустить скрипт внутри.

Dockerfile
```
FROM python:3.11.9-alpine

WORKDIR /app

ENV PYTHONUNBUFFERED=1

COPY . .

CMD ["python", "app.py"]
```
Тут каждая отдельная строка имеет свою логику при сборке образа и контейнера.

```
FROM python:3.11.9-alpine
```
**Базовый образ**, с которого начинается сборка.  
Этот образ основан на **Python 3.11.9**, собранном на базе **Alpine Linux** — это легковесная (около 5 МБ) дистрибуция, которая ускоряет сборку и уменьшает размер образа.  
Но важно помнить: для Alpine могут потребоваться дополнительные зависимости (например, `build-base`), если ты используешь библиотеки с C-расширениями.

```
WORKDIR /app
```
Устанавливает **рабочую директорию внутри контейнера**.  
Все последующие команды (например, `COPY`, `RUN`, `CMD`) будут выполняться относительно этой директории.  
Если папки `/app` не существует — она будет создана автоматически.
В рамках учебного проекта ОК, но на боевых проектах лучше пользоваться директорией usr/ и там создавать директорию проекта, потому что поведение директории usr отличается от базового.

```
ENV PYTHONUNBUFFERED=1
```
Устанавливает переменную окружения `PYTHONUNBUFFERED=1`.  
Это значит, что Python не будет буферизовать вывод (stdout/stderr), и все `print()` будут появляться в логах **сразу**, без задержки.  
Очень полезно для логирования в проде и отладки, особенно в Docker-контейнерах.

```
COPY . .
```
Копирует **все файлы из текущей директории на твоем компьютере** (`.`) **в рабочую директорию контейнера** (`.` означает `/app`, потому что мы задали `WORKDIR` ранее).  
В результате твой код, зависимости и прочие файлы окажутся внутри контейнера.

```
CMD ["python", "app.py"]
```
Указывает **команду по умолчанию**, которая запускается, когда контейнер стартует.  
Здесь — запускается файл `app.py` с помощью интерпретатора Python.  
Это не "жёсткая" команда — её можно переопределить при запуске контейнера:
```
docker run myapp python other_script.py
```

Находясь в директории с dockerfile прописываем команду
```
docker build -t timer .
```

После тега -t мы пишем имя нашему образу, после сборки можно собирать контейнер
```
docker run --name pytime -it timer
```

Контейнер запущен но мы кое-что упустили

# Установка зависимостей
Если вдруг нашему скрипту понадобятся зависимости для выполнения, как например:
```
import time
import requests


url = "https://api.binance.com/api/v3/ticker/price"
params = {
    "symbol": "BTCUSDT"
}
SLEEP_TIME = 2

while True:
    response = requests.get(url, params=params)
    data = response.json()
    print(f"Price of BTC/USDT: {data['price']}")
    time.sleep(SLEEP_TIME)
```

И в проекте есть файл `requirements.txt`
```
requests
```

```
project/
├── app.py
├── Dockerfile
└── requirements.txt
```
То нам нужно предварительно установить в наш контейнер

```
FROM python:3.11.9-alpine

WORKDIR /app

ENV PYTHONUNBUFFERED=1

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

CMD ["python", "app.py"]
```

```
COPY requirements.txt .
```
Эта команда **копирует файл `requirements.txt`** из текущей директории твоего проекта (на хост-машине) **в рабочую директорию внутри контейнера**.  
Так как ранее ты задал `WORKDIR /app`, файл попадет в контейнер как:
```
/app/requirements.txt
```

```
RUN pip install --no-cache-dir -r requirements.txt
```
Эта команда говорит Docker выполнить установку всех зависимостей, перечисленных в `requirements.txt`:
- `pip install -r requirements.txt` — стандартная команда Python для установки библиотек из списка.
    
- `--no-cache-dir` — отключает кэш pip, чтобы:
    
    - уменьшить размер итогового Docker-образа
        
    - избежать хранения временных файлов установки
